{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 121169.42\n"
     ]
    }
   ],
   "source": [
    "#problem1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ISLP import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Load Hitters dataset\n",
    "Hitters = load_data('Hitters')\n",
    "\n",
    "#Remove missing salary rows\n",
    "Hitters = Hitters.dropna(subset=['Salary'])\n",
    "\n",
    "#One-hot encode categorical variables\n",
    "X = pd.get_dummies(Hitters.drop(columns=['Salary']), drop_first=True)\n",
    "y = Hitters['Salary']\n",
    "\n",
    "#Split data 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "#Fit Bagging model (RF with all predictors)\n",
    "rf_bagging = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_features=X.shape[1],  # use all predictors Bagging\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_bagging.fit(X_train, y_train)\n",
    "\n",
    "#Predict and compute test MSE\n",
    "y_pred = rf_bagging.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Test MSE: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ded185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 121789.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c5a605d1-2919-46dd-8bcd-21516d38abf4",
       "rows": [
        [
         "0",
         "CHits",
         "0.14176768176702986"
        ],
        [
         "1",
         "CAtBat",
         "0.11760685962723352"
        ],
        [
         "2",
         "CRBI",
         "0.11057185929156525"
        ],
        [
         "3",
         "CRuns",
         "0.10421929567459043"
        ],
        [
         "4",
         "CHmRun",
         "0.07249044524860143"
        ],
        [
         "5",
         "CWalks",
         "0.06481600238313641"
        ],
        [
         "6",
         "PutOuts",
         "0.0556627666412897"
        ],
        [
         "7",
         "RBI",
         "0.05161878538343416"
        ],
        [
         "8",
         "Hits",
         "0.047646653348484516"
        ],
        [
         "9",
         "AtBat",
         "0.047064941111190015"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHits</td>\n",
       "      <td>0.141768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAtBat</td>\n",
       "      <td>0.117607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRBI</td>\n",
       "      <td>0.110572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRuns</td>\n",
       "      <td>0.104219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHmRun</td>\n",
       "      <td>0.072490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CWalks</td>\n",
       "      <td>0.064816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PutOuts</td>\n",
       "      <td>0.055663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RBI</td>\n",
       "      <td>0.051619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hits</td>\n",
       "      <td>0.047647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AtBat</td>\n",
       "      <td>0.047065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Importance\n",
       "0    CHits    0.141768\n",
       "1   CAtBat    0.117607\n",
       "2     CRBI    0.110572\n",
       "3    CRuns    0.104219\n",
       "4   CHmRun    0.072490\n",
       "5   CWalks    0.064816\n",
       "6  PutOuts    0.055663\n",
       "7      RBI    0.051619\n",
       "8     Hits    0.047647\n",
       "9    AtBat    0.047065"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#problem2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#X_train, X_test, y_train, y_test assumed to be already defined from previous code\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_features=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#MSE\n",
    "y_pred = rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse_rf:.2f}\")\n",
    "\n",
    "#Feature Importance DataFrame\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf.feature_importances_\n",
    "    })\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "importance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f002e2",
   "metadata": {},
   "source": [
    "The variable CHits has the highest importance score (â‰ˆ 0.14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.821\n"
     ]
    }
   ],
   "source": [
    "#problem3\n",
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Load OJ dataset\n",
    "OJ = load_data('OJ')\n",
    "\n",
    "#Define features and target\n",
    "X = pd.get_dummies(OJ.drop(columns=['Purchase']), drop_first=True)\n",
    "y = OJ['Purchase']\n",
    "\n",
    "#Split data into training (75%) and test (25%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Fit decision tree classifier\n",
    "tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "#Predict and compute accuracy\n",
    "y_pred = tree.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93d2fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'name' column not found. This is expected because the ISLP version of the Auto dataset has already removed the 'name' variable compared to the original ISLR version.\n",
      "\n",
      "Test Accuracy: 0.932\n"
     ]
    }
   ],
   "source": [
    "#problem4\n",
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Load Auto dataset\n",
    "Auto = load_data('Auto')\n",
    "\n",
    "#Check if 'name' column exists\n",
    "if 'name' in Auto.columns:\n",
    "    print(\"'name' column found in the dataset.\")\n",
    "else:\n",
    "    print(\"'name' column not found. This is expected because the ISLP version of the Auto dataset \"\n",
    "          \"has already removed the 'name' variable compared to the original ISLR version.\")\n",
    "\n",
    "#Drop rows with missing values\n",
    "Auto = Auto.dropna()\n",
    "\n",
    "#Create binary target: 1 if mpg > median(mpg), else 0\n",
    "median_mpg = Auto['mpg'].median()\n",
    "Auto['mpg_high'] = (Auto['mpg'] > median_mpg).astype(int)\n",
    "\n",
    "#Define features and target\n",
    "#Only drop 'mpg' (not 'name', since it's not present)\n",
    "X = pd.get_dummies(Auto.drop(columns=['mpg', 'mpg_high']), drop_first=True)\n",
    "y = Auto['mpg_high']\n",
    "\n",
    "#Split into training and test sets (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#Fit Gradient Boosting Classifier\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "#Predict and compute accuracy\n",
    "y_pred = gb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {acc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bb011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) Number of leaf nodes: 4\n",
      "(b) Test MSE: 161392.55\n"
     ]
    }
   ],
   "source": [
    "#problem5\n",
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "#Load dataset and drop rows with missing Salary\n",
    "Hitters = load_data('Hitters').dropna(subset=['Salary'])\n",
    "\n",
    "#One-hot encode categorical variables\n",
    "X = pd.get_dummies(Hitters.drop(columns=['Salary']), drop_first=True)\n",
    "y = Hitters['Salary']\n",
    "\n",
    "#Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "#Fit initial regression tree\n",
    "base_tree = DecisionTreeRegressor(max_depth=6, random_state=42)\n",
    "base_tree.fit(X_train, y_train)\n",
    "\n",
    "#Get cost complexity pruning path (ccp_alpha values)\n",
    "path = base_tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "#Grid search for best ccp_alpha (5-fold CV)\n",
    "param_grid = {'ccp_alpha': ccp_alphas}\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeRegressor(max_depth=6, random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate best estimator\n",
    "best_tree = grid.best_estimator_\n",
    "n_leaves = best_tree.get_n_leaves()\n",
    "test_mse = mean_squared_error(y_test, best_tree.predict(X_test))\n",
    "\n",
    "print(f\"(a) Number of leaf nodes: {n_leaves}\")\n",
    "print(f\"(b) Test MSE: {test_mse:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
