{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a7a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (10000, 4)\n",
      "\n",
      "Column names and data types:\n",
      " default    category\n",
      "student    category\n",
      "balance     float64\n",
      "income      float64\n",
      "dtype: object\n",
      "\n",
      "Distribution of the default variable:\n",
      " default\n",
      "No     9667\n",
      "Yes     333\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Problem1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ISLP import load_data\n",
    "\n",
    "Default = load_data('Default')\n",
    "\n",
    "# Report the dataset dimensions\n",
    "print(\"Dataset dimensions:\", Default.shape)\n",
    "# Report the column names and their data types\n",
    "print(\"\\nColumn names and data types:\\n\", Default.dtypes)\n",
    "# Report the distribution of the default variable\n",
    "print(\"\\nDistribution of the default variable:\\n\", Default['default'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "804140dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078577\n",
      "         Iterations 10\n",
      "\n",
      "Logit Model Summary:\n",
      "                            Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            default_bin   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Fri, 26 Sep 2025   Pseudo R-squ.:                  0.4619\n",
      "Time:                        12:02:25   Log-Likelihood:                -785.77\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.257e-292\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept        -10.8690      0.492    -22.079      0.000     -11.834      -9.904\n",
      "student[T.Yes]    -0.6468      0.236     -2.738      0.006      -1.110      -0.184\n",
      "balance            0.0057      0.000     24.737      0.000       0.005       0.006\n",
      "income          3.033e-06    8.2e-06      0.370      0.712    -1.3e-05    1.91e-05\n",
      "==================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.15 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "Balance coefficient: 0.005736505265799079\n",
      "\n",
      "Odds Ratios:\n",
      " Intercept         0.000019\n",
      "student[T.Yes]    0.523732\n",
      "balance           1.005753\n",
      "income            1.000003\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "# Create logit miodel\n",
    "Default['default_bin'] = (Default['default'] == 'Yes').astype(int)\n",
    "logit_model = smf.logit('default_bin ~ student + balance + income', data=Default).fit()\n",
    "\n",
    "# Report the summary of the model\n",
    "print(\"\\nLogit Model Summary:\\n\", logit_model.summary())\n",
    "\n",
    "print(\"Balance coefficient:\", logit_model.params['balance'])\n",
    "\n",
    "# Report the odds ratios for the coefficients\n",
    "odds_ratios = pd.Series(np.exp(logit_model.params), index=logit_model.params.index)\n",
    "print(\"\\nOdds Ratios:\\n\", odds_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa8f21",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The dataset has 10,000 observations and 4 variables (default, student, balance, income).\n",
    "\n",
    "The default variable has 9674 \"No\" and 326 \"Yes\".\n",
    "\n",
    "In the logistic regression model predicting default from income, balance, and student, the coefficient for **balance** is approximately 0.0055.\n",
    "\n",
    "Interpretation: A one-unit increase in balance raises the log-odds of defaulting by 0.0055. Equivalently, each extra dollar increases the odds of defaulting by about 0.55%, controlling for income and student status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ba993c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use imcone and balance as predictors\n",
    "X = Default[['income', 'balance']]\n",
    "y = (Default['default'] == 'Yes').astype(int) \n",
    "# Split 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bf22e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Class Means:\n",
      " [[33530.99663426   806.21587478]\n",
      " [31626.77324835  1744.36429028]]\n",
      "\n",
      "LDA Prior Probabilities:\n",
      " [0.96671429 0.03328571]\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Report class means\n",
    "print(\"\\nLDA Class Means:\\n\", lda.means_)\n",
    "# Report prior probabilities\n",
    "print(\"\\nLDA Prior Probabilities:\\n\", lda.priors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "397be506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class means: [[33530.99663426   806.21587478]\n",
      " [31626.77324835  1744.36429028]]\n",
      "Class priors: [0.96671429 0.03328571]\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "print(\"Class means:\", qda.means_)\n",
    "print(\"Class priors:\", qda.priors_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fde1c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Confusion Matrix:\n",
      " [[2891    9]\n",
      " [  74   26]]\n",
      "LDA Test Accuracy: 0.9723333333333334\n",
      "\n",
      "QDA Confusion Matrix:\n",
      " [[2886   14]\n",
      " [  71   29]]\n",
      "QDA Test Accuracy: 0.9716666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# LDA predictions\n",
    "y_pred_lda = lda.predict(X_test)\n",
    "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
    "acc_lda = accuracy_score(y_test, y_pred_lda)\n",
    "\n",
    "print(\"\\nLDA Confusion Matrix:\\n\", cm_lda)\n",
    "print(\"LDA Test Accuracy:\", acc_lda)\n",
    "\n",
    "# QDA predictions\n",
    "y_pred_qda = qda.predict(X_test)\n",
    "cm_qda = confusion_matrix(y_test, y_pred_qda)\n",
    "acc_qda = accuracy_score(y_test, y_pred_qda)\n",
    "\n",
    "print(\"\\nQDA Confusion Matrix:\\n\", cm_qda)\n",
    "print(\"QDA Test Accuracy:\", acc_qda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156529b7",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Both LDA and QDA achieve very high overall accuracy (about 97%), mainly because most customers do not default.\n",
    "\n",
    "The class means show that defaulting customers tend to have higher balances and lower incomes compared to non-defaulters.\n",
    "\n",
    "The priors reflect the strong class imbalance (about 3% defaults).\n",
    "\n",
    "LDA correctly classifies most “No” cases but misses many “Yes” cases (74 false negatives vs. 26 true positives).\n",
    "\n",
    "QDA performs similarly, with slightly lower accuracy on “No” but slightly better detection of “Yes.”\n",
    "\n",
    "Overall, balance is the most important variable for distinguishing default status, while the models struggle to capture the minority “Yes” cases due to data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a5bdee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Confusion Matrix:\n",
      " [[2883   17]\n",
      " [  73   27]]\n",
      "Naive Bayes Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Problem 3\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"\\nNaive Bayes Confusion Matrix:\\n\", cm_nb)\n",
    "print(\"Naive Bayes Test Accuracy:\", acc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45242889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50059302, 0.49940698]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_data = pd.DataFrame([[40000, 2000]], columns=['income', 'balance'])\n",
    "nb.predict_proba(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe5b10",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Naive Bayes classifier\n",
    "\n",
    "Trained with income and balance as predictors, the test accuracy is about 97%.\n",
    "\n",
    "Overall accuracy (97%) is slightly lower than LDA (97.23%) and QDA (97.16%).\n",
    "\n",
    "#### Confusion matrix results\n",
    "\n",
    "Similar to LDA and QDA, most “No default” cases are classified correctly.\n",
    "\n",
    "The model has weaker performance in identifying “Yes default” cases, with more misclassifications.\n",
    "\n",
    "#### Prediction for a new customer\n",
    "\n",
    "For income = 40,000 and balance = 2,000, the predicted probability of default is about 0.50.\n",
    "\n",
    "This means the customer has nearly equal chances of defaulting or not defaulting.\n",
    "\n",
    "#### Overall conclusion\n",
    "\n",
    "All three models achieve high accuracy on the imbalanced dataset, but mainly by correctly predicting “No.”\n",
    "\n",
    "Balance is the most important predictor of default, while income contributes very little.\n",
    "\n",
    "LDA and QDA perform slightly better than Naive Bayes, as they can model correlations between predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38d80f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (k=1) Test Accuracy: 0.9583333333333334\n",
      "KNN (k=3) Test Accuracy: 0.9673333333333334\n",
      "KNN (k=5) Test Accuracy: 0.968\n",
      "KNN (k=10) Test Accuracy: 0.9703333333333334\n",
      "\n",
      "Summary Table:\n",
      "    Test Accuracy\n",
      "1        0.958333\n",
      "3        0.967333\n",
      "5        0.968000\n",
      "10       0.970333\n"
     ]
    }
   ],
   "source": [
    "# Problem 4\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Try KNN with k=1,3,5,10\n",
    "k_values = [1, 3, 5, 10]\n",
    "results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred_knn = knn.predict(X_test_scaled)\n",
    "    acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    results[k] = acc_knn  \n",
    "    print(f\"KNN (k={k}) Test Accuracy:\", acc_knn)\n",
    "\n",
    "# Create table\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Test Accuracy'])\n",
    "print(\"\\nSummary Table:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d708c",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "The best performance is obtained at K = 10, with a test accuracy of about 97.0%.\n",
    "\n",
    "Very small values of K (K = 1) tend to perform worse because the classifier is overly sensitive to noise or outliers: the prediction for a test point depends entirely on a single nearest neighbor, which may not represent the broader pattern.\n",
    "\n",
    "As K increases, the decision boundary becomes smoother (as the graph shown in class), reducing variance and improving generalization.\n",
    "\n",
    "However, if K is set too large, the model may become too biased by averaging over many neighbors and ignore local structure — so there is a trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f1915ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078110\n",
      "         Iterations 10\n",
      "Logistic Regression Test Accuracy: 0.9716666666666667\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[2882   18]\n",
      " [  67   33]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Logistic accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = Default[['student', 'balance', 'income']]\n",
    "y = Default['default_bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "train = X_train.copy()\n",
    "train['default_bin'] = y_train\n",
    "\n",
    "test = X_test.copy()\n",
    "test['default_bin'] = y_test\n",
    "\n",
    "# logistic regression (refit on training data)\n",
    "logit_model = smf.logit('default_bin ~ student + balance + income', data=train).fit()\n",
    "y_pred_prob = logit_model.predict(test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "acc_logit = accuracy_score(test['default_bin'], y_pred)\n",
    "\n",
    "print(\"Logistic Regression Test Accuracy:\", acc_logit)\n",
    "\n",
    "# confusion matrix\n",
    "cm_logit = confusion_matrix(test['default_bin'], y_pred)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", cm_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b21d8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Confusion Matrix:\n",
      " [[2878   22]\n",
      " [  67   33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# use k=10 as an example cuz is the best performance\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"KNN Confusion Matrix:\\n\", cm_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7002ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression FNR: 0.67\n",
      "LDA FNR: 0.74\n",
      "QDA FNR: 0.71\n",
      "Naive Bayes FNR: 0.73\n",
      "KNN FNR: 0.67\n"
     ]
    }
   ],
   "source": [
    "fnr_logit = cm_logit[1,0] / (cm_logit[1,0] + cm_logit[1,1])\n",
    "fnr_lda  = cm_lda[1,0]  / (cm_lda[1,0]  + cm_lda[1,1])\n",
    "fnr_qda  = cm_qda[1,0]  / (cm_qda[1,0]  + cm_qda[1,1])\n",
    "fnr_nb   = cm_nb[1,0]   / (cm_nb[1,0]   + cm_nb[1,1])\n",
    "fnr_knn   = cm_knn[1,0]   / (cm_knn[1,0]   + cm_knn[1,1])\n",
    "\n",
    "print(\"Logistic Regression FNR:\", fnr_logit)\n",
    "print(\"LDA FNR:\", fnr_lda)\n",
    "print(\"QDA FNR:\", fnr_qda)\n",
    "print(\"Naive Bayes FNR:\", fnr_nb)\n",
    "print(\"KNN FNR:\", fnr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc4d0447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (threshold 0.5) -> FPR: 0.006206896551724138 FNR: 0.67 CM: [[2882   18]\n",
      " [  67   33]]\n",
      "Logistic Regression (threshold 0.3) -> FPR: 0.019655172413793102 FNR: 0.47 CM: [[2843   57]\n",
      " [  47   53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def rates_from_cm(cm):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    # False Positive Rate (FPR) = FP / (FP + TN)\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    # False Negative Rate (FNR) = FN / (FN + TP)\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "    return fpr, fnr, (tn, fp, fn, tp)\n",
    "\n",
    "# Predicted probabilities on the test set\n",
    "y_prob_logit = logit_model.predict(test)\n",
    "\n",
    "# Threshold = 0.5\n",
    "y_pred_05 = (y_prob_logit > 0.5).astype(int)\n",
    "cm_05 = confusion_matrix(test['default_bin'], y_pred_05)\n",
    "fpr_05, fnr_05, _ = rates_from_cm(cm_05)\n",
    "\n",
    "# Threshold = 0.3\n",
    "y_pred_03 = (y_prob_logit > 0.3).astype(int)\n",
    "cm_03 = confusion_matrix(test['default_bin'], y_pred_03)\n",
    "fpr_03, fnr_03, _ = rates_from_cm(cm_03)\n",
    "\n",
    "print(\"Logistic Regression (threshold 0.5) -> FPR:\", fpr_05, \"FNR:\", fnr_05, \"CM:\", cm_05)\n",
    "print(\"Logistic Regression (threshold 0.3) -> FPR:\", fpr_03, \"FNR:\", fnr_03, \"CM:\", cm_03)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4ddb9",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "#### Summary Table of Test Accuracy\n",
    "\n",
    "| Method              | Test Accuracy |\n",
    "|---------------------|---------------|\n",
    "| Logistic Regression | 0.9717        |\n",
    "| LDA                 | 0.9723        |\n",
    "| QDA                 | 0.9717        |\n",
    "| Naive Bayes         | 0.9700        |\n",
    "| KNN (k=1)           | 0.9583        |\n",
    "| KNN (k=3)           | 0.9673        |\n",
    "| KNN (k=5)           | 0.9680        |\n",
    "| KNN (k=10, best)    | 0.9703        |\n",
    "\n",
    "#### False Negative Rate (FNR) Comparison\n",
    "\n",
    "| Method              | FNR  |\n",
    "|---------------------|------|\n",
    "| Logistic Regression | 0.67 |\n",
    "| LDA                 | 0.74 |\n",
    "| QDA                 | 0.71 |\n",
    "| Naive Bayes         | 0.73 |\n",
    "| KNN (k=10)          | 0.67 |\n",
    "\n",
    "Lowest FNR: Logistic Regression (0.67) and KNN (0.67)\n",
    "\n",
    "#### Cost-sensitive recommendation\n",
    "\n",
    "Since missing a default (FN) costs 10× more than a false alarm (FP), the method with the lowest false negative rate (FNR) is preferred.\n",
    "\n",
    "Logistic Regression already had one of the lowest FNRs (0.67) while also maintaining very high test accuracy (97.17%).\n",
    "\n",
    "It is also easy to tune using probability thresholds, making it the most appropriate choice.\n",
    "\n",
    "#### Effect of lowering the threshold (0.5 to 0.3)\n",
    "\n",
    "| Threshold | Confusion Matrix        | FPR   | FNR   | Interpretation                       |\n",
    "|-----------|-------------------------|-------|-------|--------------------------------------|\n",
    "| 0.5       | [[2882, 18], [67, 33]] | 0.006 | 0.67  | Very low FPR, but misses most defaults |\n",
    "| 0.3       | [[2843, 57], [47, 53]] | 0.020 | 0.47  | Higher FPR, but catches more defaults |\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Lowering the threshold significantly reduces false negatives (catching more defaults) at the expense of a modest increase in false positives. Given the cost imbalance, this trade-off makes Logistic Regression at a 0.3 threshold the best choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
