{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a7a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (10000, 4)\n",
      "\n",
      "Column names and data types:\n",
      " default    category\n",
      "student    category\n",
      "balance     float64\n",
      "income      float64\n",
      "dtype: object\n",
      "\n",
      "Distribution of the default variable:\n",
      " default\n",
      "No     9667\n",
      "Yes     333\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Problem1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ISLP import load_data\n",
    "\n",
    "Default = load_data('Default')\n",
    "\n",
    "# Report the dataset dimensions\n",
    "print(\"Dataset dimensions:\", Default.shape)\n",
    "# Report the column names and their data types\n",
    "print(\"\\nColumn names and data types:\\n\", Default.dtypes)\n",
    "# Report the distribution of the default variable\n",
    "print(\"\\nDistribution of the default variable:\\n\", Default['default'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "804140dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078577\n",
      "         Iterations 10\n",
      "\n",
      "Logit Model Summary:\n",
      "                            Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            default_bin   No. Observations:                10000\n",
      "Model:                          Logit   Df Residuals:                     9996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Fri, 26 Sep 2025   Pseudo R-squ.:                  0.4619\n",
      "Time:                        11:54:40   Log-Likelihood:                -785.77\n",
      "converged:                       True   LL-Null:                       -1460.3\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.257e-292\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept        -10.8690      0.492    -22.079      0.000     -11.834      -9.904\n",
      "student[T.Yes]    -0.6468      0.236     -2.738      0.006      -1.110      -0.184\n",
      "balance            0.0057      0.000     24.737      0.000       0.005       0.006\n",
      "income          3.033e-06    8.2e-06      0.370      0.712    -1.3e-05    1.91e-05\n",
      "==================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.15 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "Balance coefficient: 0.005736505265799079\n",
      "\n",
      "Odds Ratios:\n",
      " Intercept         0.000019\n",
      "student[T.Yes]    0.523732\n",
      "balance           1.005753\n",
      "income            1.000003\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "# Create logit miodel\n",
    "Default['default_bin'] = (Default['default'] == 'Yes').astype(int)\n",
    "logit_model = smf.logit('default_bin ~ student + balance + income', data=Default).fit()\n",
    "\n",
    "# Report the summary of the model\n",
    "print(\"\\nLogit Model Summary:\\n\", logit_model.summary())\n",
    "\n",
    "print(\"Balance coefficient:\", logit_model.params['balance'])\n",
    "\n",
    "# Report the odds ratios for the coefficients\n",
    "odds_ratios = pd.Series(np.exp(logit_model.params), index=logit_model.params.index)\n",
    "print(\"\\nOdds Ratios:\\n\", odds_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa8f21",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The dataset has 10,000 observations and 4 variables (default, student, balance, income).\n",
    "\n",
    "The default variable has 9674 \"No\" and 326 \"Yes\".\n",
    "\n",
    "In the logistic regression model predicting default from income, balance, and student, the coefficient for **balance** is approximately 0.0055.\n",
    "\n",
    "Interpretation: A one-unit increase in balance raises the log-odds of defaulting by 0.0055. Equivalently, each extra dollar increases the odds of defaulting by about 0.55%, controlling for income and student status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba993c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#use imcone and balance as predictors\n",
    "X = Default[['income', 'balance']]\n",
    "y = (Default['default'] == 'Yes').astype(int) \n",
    "# Split 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf22e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Class Means:\n",
      " [[33530.99663426   806.21587478]\n",
      " [31626.77324835  1744.36429028]]\n",
      "\n",
      "LDA Prior Probabilities:\n",
      " [0.96671429 0.03328571]\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Report class means\n",
    "print(\"\\nLDA Class Means:\\n\", lda.means_)\n",
    "# Report prior probabilities\n",
    "print(\"\\nLDA Prior Probabilities:\\n\", lda.priors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397be506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuadraticDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>QuadraticDiscriminantAnalysis</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html\">?<span>Documentation for QuadraticDiscriminantAnalysis</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">priors&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_param',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_param&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('store_covariance',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">store_covariance&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "QuadraticDiscriminantAnalysis()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 2\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fde1c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Confusion Matrix:\n",
      " [[2891    9]\n",
      " [  74   26]]\n",
      "LDA Test Accuracy: 0.9723333333333334\n",
      "\n",
      "QDA Confusion Matrix:\n",
      " [[2886   14]\n",
      " [  71   29]]\n",
      "QDA Test Accuracy: 0.9716666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# LDA predictions\n",
    "y_pred_lda = lda.predict(X_test)\n",
    "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
    "acc_lda = accuracy_score(y_test, y_pred_lda)\n",
    "\n",
    "print(\"\\nLDA Confusion Matrix:\\n\", cm_lda)\n",
    "print(\"LDA Test Accuracy:\", acc_lda)\n",
    "\n",
    "# QDA predictions\n",
    "y_pred_qda = qda.predict(X_test)\n",
    "cm_qda = confusion_matrix(y_test, y_pred_qda)\n",
    "acc_qda = accuracy_score(y_test, y_pred_qda)\n",
    "\n",
    "print(\"\\nQDA Confusion Matrix:\\n\", cm_qda)\n",
    "print(\"QDA Test Accuracy:\", acc_qda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156529b7",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Both LDA and QDA achieve very high overall accuracy (about 97%), mainly because most customers do not default.\n",
    "\n",
    "The class means show that defaulting customers tend to have higher balances and lower incomes compared to non-defaulters.\n",
    "\n",
    "The priors reflect the strong class imbalance (about 3% defaults).\n",
    "\n",
    "LDA correctly classifies most “No” cases but misses many “Yes” cases (74 false negatives vs. 26 true positives).\n",
    "\n",
    "QDA performs similarly, with slightly lower accuracy on “No” but slightly better detection of “Yes.”\n",
    "\n",
    "Overall, balance is the most important variable for distinguishing default status, while the models struggle to capture the minority “Yes” cases due to data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5bdee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Confusion Matrix:\n",
      " [[2883   17]\n",
      " [  73   27]]\n",
      "Naive Bayes Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Problem 3\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"\\nNaive Bayes Confusion Matrix:\\n\", cm_nb)\n",
    "print(\"Naive Bayes Test Accuracy:\", acc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45242889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities [No, Yes]: [[0.50059302 0.49940698]]\n",
      "Probability of default: 0.4994069795081303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_data = [[40000, 2000]]   # shape = (1, 2)\n",
    "prob_default = nb.predict_proba(new_data)\n",
    "\n",
    "print(\"Predicted probabilities [No, Yes]:\", prob_default)\n",
    "print(\"Probability of default:\", prob_default[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe5b10",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "**Naive Bayes classifier**\n",
    "\n",
    "Trained with income and balance as predictors, the test accuracy is about 97%.\n",
    "\n",
    "Overall accuracy (97%) is slightly lower than LDA (97.23%) and QDA (97.16%).\n",
    "\n",
    "**Confusion matrix results**\n",
    "\n",
    "Similar to LDA and QDA, most “No default” cases are classified correctly.\n",
    "\n",
    "The model has weaker performance in identifying “Yes default” cases, with more misclassifications.\n",
    "\n",
    "**Prediction for a new customer**\n",
    "\n",
    "For income = 40,000 and balance = 2,000, the predicted probability of default is about 0.50.\n",
    "\n",
    "This means the customer has nearly equal chances of defaulting or not defaulting.\n",
    "\n",
    "**Overall conclusion**\n",
    "\n",
    "All three models achieve high accuracy on the imbalanced dataset, but mainly by correctly predicting “No.”\n",
    "\n",
    "Balance is the most important predictor of default, while income contributes very little.\n",
    "\n",
    "LDA and QDA perform slightly better than Naive Bayes, as they can model correlations between predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d80f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (k=1) Test Accuracy: 0.9583333333333334\n",
      "KNN (k=3) Test Accuracy: 0.9673333333333334\n",
      "KNN (k=5) Test Accuracy: 0.968\n",
      "KNN (k=10) Test Accuracy: 0.9703333333333334\n",
      "\n",
      "Summary Table:\n",
      "    Test Accuracy\n",
      "1        0.958333\n",
      "3        0.967333\n",
      "5        0.968000\n",
      "10       0.970333\n"
     ]
    }
   ],
   "source": [
    "# Problem 4\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#standardize the predictors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Try KNN with k=1,3,5,10\n",
    "k_values = [1, 3, 5, 10]\n",
    "results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred_knn = knn.predict(X_test_scaled)\n",
    "    acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    results[k] = acc_knn  \n",
    "    print(f\"KNN (k={k}) Test Accuracy:\", acc_knn)\n",
    "\n",
    "# Create table\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Test Accuracy'])\n",
    "print(\"\\nSummary Table:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d708c",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "The best performance is obtained at K = 10, with a test accuracy of about 97.0%.\n",
    "\n",
    "Very small values of K (K = 1) tend to perform worse because the classifier is overly sensitive to noise or outliers: the prediction for a test point depends entirely on a single nearest neighbor, which may not represent the broader pattern.\n",
    "\n",
    "As K increases, the decision boundary becomes smoother (as the graph shown in class), reducing variance and improving generalization.\n",
    "\n",
    "However, if K is set too large, the model may become too biased by averaging over many neighbors and ignore local structure — so there is a trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f1915ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078110\n",
      "         Iterations 10\n",
      "Logistic Regression Test Accuracy: 0.9716666666666667\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[2882   18]\n",
      " [  67   33]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Logistic accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = Default[['student', 'balance', 'income']]\n",
    "y = Default['default_bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "train = X_train.copy()\n",
    "train['default_bin'] = y_train\n",
    "\n",
    "test = X_test.copy()\n",
    "test['default_bin'] = y_test\n",
    "\n",
    "# logistic regression (refit on training data)\n",
    "logit_model = smf.logit('default_bin ~ student + balance + income', data=train).fit()\n",
    "y_pred_prob = logit_model.predict(test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "acc_logit = accuracy_score(test['default_bin'], y_pred)\n",
    "\n",
    "print(\"Logistic Regression Test Accuracy:\", acc_logit)\n",
    "\n",
    "# confusion matrix\n",
    "cm_logit = confusion_matrix(test['default_bin'], y_pred)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", cm_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b21d8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Confusion Matrix:\n",
      " [[2878   22]\n",
      " [  67   33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# use k=10 as an example cuz is the best performance\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"KNN Confusion Matrix:\\n\", cm_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7002ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression FNR: 0.67\n",
      "LDA FNR: 0.74\n",
      "QDA FNR: 0.71\n",
      "Naive Bayes FNR: 0.73\n",
      "KNN FNR: 0.67\n"
     ]
    }
   ],
   "source": [
    "fnr_logit = cm_logit[1,0] / (cm_logit[1,0] + cm_logit[1,1])\n",
    "fnr_lda  = cm_lda[1,0]  / (cm_lda[1,0]  + cm_lda[1,1])\n",
    "fnr_qda  = cm_qda[1,0]  / (cm_qda[1,0]  + cm_qda[1,1])\n",
    "fnr_nb   = cm_nb[1,0]   / (cm_nb[1,0]   + cm_nb[1,1])\n",
    "fnr_knn   = cm_knn[1,0]   / (cm_knn[1,0]   + cm_knn[1,1])\n",
    "\n",
    "print(\"Logistic Regression FNR:\", fnr_logit)\n",
    "print(\"LDA FNR:\", fnr_lda)\n",
    "print(\"QDA FNR:\", fnr_qda)\n",
    "print(\"Naive Bayes FNR:\", fnr_nb)\n",
    "print(\"KNN FNR:\", fnr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc4d0447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (threshold 0.5) -> FPR: 0.006206896551724138 FNR: 0.67 CM: [[2882   18]\n",
      " [  67   33]]\n",
      "Logistic Regression (threshold 0.3) -> FPR: 0.019655172413793102 FNR: 0.47 CM: [[2843   57]\n",
      " [  47   53]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def rates_from_cm(cm):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    # False Positive Rate (FPR) = FP / (FP + TN)\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    # False Negative Rate (FNR) = FN / (FN + TP)\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "    return fpr, fnr, (tn, fp, fn, tp)\n",
    "\n",
    "# Predicted probabilities on the test set\n",
    "y_prob_logit = logit_model.predict(test)\n",
    "\n",
    "# Threshold = 0.5\n",
    "y_pred_05 = (y_prob_logit > 0.5).astype(int)\n",
    "cm_05 = confusion_matrix(test['default_bin'], y_pred_05)\n",
    "fpr_05, fnr_05, _ = rates_from_cm(cm_05)\n",
    "\n",
    "# Threshold = 0.3\n",
    "y_pred_03 = (y_prob_logit > 0.3).astype(int)\n",
    "cm_03 = confusion_matrix(test['default_bin'], y_pred_03)\n",
    "fpr_03, fnr_03, _ = rates_from_cm(cm_03)\n",
    "\n",
    "print(\"Logistic Regression (threshold 0.5) -> FPR:\", fpr_05, \"FNR:\", fnr_05, \"CM:\", cm_05)\n",
    "print(\"Logistic Regression (threshold 0.3) -> FPR:\", fpr_03, \"FNR:\", fnr_03, \"CM:\", cm_03)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4ddb9",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "#### Summary Table of Test Accuracy\n",
    "\n",
    "| Method              | Test Accuracy |\n",
    "|---------------------|---------------|\n",
    "| Logistic Regression | 0.9717        |\n",
    "| LDA                 | 0.9723        |\n",
    "| QDA                 | 0.9717        |\n",
    "| Naive Bayes         | 0.9700        |\n",
    "| KNN (k=1)           | 0.9583        |\n",
    "| KNN (k=3)           | 0.9673        |\n",
    "| KNN (k=5)           | 0.9680        |\n",
    "| KNN (k=10, best)    | 0.9703        |\n",
    "\n",
    "#### False Negative Rate (FNR) Comparison\n",
    "\n",
    "| Method              | FNR  |\n",
    "|---------------------|------|\n",
    "| Logistic Regression | 0.67 |\n",
    "| LDA                 | 0.74 |\n",
    "| QDA                 | 0.71 |\n",
    "| Naive Bayes         | 0.73 |\n",
    "| KNN (k=10)          | 0.67 |\n",
    "\n",
    "Lowest FNR: Logistic Regression (0.67) and KNN (0.67)\n",
    "\n",
    "#### Cost-sensitive recommendation\n",
    "\n",
    "Since missing a default (FN) costs 10× more than a false alarm (FP), the method with the lowest false negative rate (FNR) is preferred.\n",
    "\n",
    "Logistic Regression already had one of the lowest FNRs (0.67) while also maintaining very high test accuracy (97.17%).\n",
    "\n",
    "It is also easy to tune using probability thresholds, making it the most appropriate choice.\n",
    "\n",
    "#### Effect of lowering the threshold (0.5 to 0.3)\n",
    "\n",
    "| Threshold | Confusion Matrix        | FPR   | FNR   | Interpretation                       |\n",
    "|-----------|-------------------------|-------|-------|--------------------------------------|\n",
    "| 0.5       | [[2882, 18], [67, 33]] | 0.006 | 0.67  | Very low FPR, but misses most defaults |\n",
    "| 0.3       | [[2843, 57], [47, 53]] | 0.020 | 0.47  | Higher FPR, but catches more defaults |\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Lowering the threshold significantly reduces false negatives (catching more defaults) at the expense of a modest increase in false positives. Given the cost imbalance, this trade-off makes Logistic Regression at a 0.3 threshold the best choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
