{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32ddeb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ISLP in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (2.3.2)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (1.16.2)\n",
      "Requirement already satisfied: pandas>=0.20 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (2.3.2)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (1.7.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (1.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (0.14.5)\n",
      "Requirement already satisfied: lifelines in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (0.30.0)\n",
      "Requirement already satisfied: pygam in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (0.10.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (2.8.0)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (2.5.5)\n",
      "Requirement already satisfied: torchmetrics in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from ISLP) (1.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pandas>=0.20->ISLP) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pandas>=0.20->ISLP) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pandas>=0.20->ISLP) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.20->ISLP) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from scikit-learn>=1.2->ISLP) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from statsmodels>=0.13->ISLP) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from statsmodels>=0.13->ISLP) (25.0)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from lifelines->ISLP) (3.10.6)\n",
      "Requirement already satisfied: autograd>=1.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from lifelines->ISLP) (1.8.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from lifelines->ISLP) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from lifelines->ISLP) (1.2.0)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.17 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from formulaic>=0.2.2->lifelines->ISLP) (1.17.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from matplotlib>=3.0->lifelines->ISLP) (3.2.3)\n",
      "Requirement already satisfied: progressbar2<5,>=4.2.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pygam->ISLP) (4.5.0)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from progressbar2<5,>=4.2.0->pygam->ISLP) (3.9.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>5.4 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2025.9.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from pytorch-lightning->ISLP) (0.15.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->ISLP) (3.10)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning->ISLP) (78.1.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch->ISLP) (3.19.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch->ISLP) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch->ISLP) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from torch->ISLP) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from sympy>=1.13.3->torch->ISLP) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/myenv/lib/python3.11/site-packages (from jinja2->torch->ISLP) (3.0.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "radio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "newspaper",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "db330712-8b41-4082-a0cd-cac4cec12c1d",
       "rows": [
        [
         "0",
         "1",
         "230.1",
         "37.8",
         "69.2",
         "22.1"
        ],
        [
         "1",
         "2",
         "44.5",
         "39.3",
         "45.1",
         "10.4"
        ],
        [
         "2",
         "3",
         "17.2",
         "45.9",
         "69.3",
         "9.3"
        ],
        [
         "3",
         "4",
         "151.5",
         "41.3",
         "58.5",
         "18.5"
        ],
        [
         "4",
         "5",
         "180.8",
         "10.8",
         "58.4",
         "12.9"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  radio  newspaper  sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Coefficient",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Std. error",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t-statistic",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p-value",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "7e8835e0-ad1a-455e-baad-0d603be67739",
       "rows": [
        [
         "Intercept",
         "2.939",
         "0.3119",
         "9.42",
         "<0.0001"
        ],
        [
         "TV",
         "0.046",
         "0.0014",
         "32.81",
         "<0.0001"
        ],
        [
         "radio",
         "0.189",
         "0.0086",
         "21.89",
         "<0.0001"
        ],
        [
         "newspaper",
         "-0.001",
         "0.0059",
         "-0.18",
         "0.8599"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std. error</th>\n",
       "      <th>t-statistic</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>2.939</td>\n",
       "      <td>0.3119</td>\n",
       "      <td>9.42</td>\n",
       "      <td>&lt;0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>0.046</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>32.81</td>\n",
       "      <td>&lt;0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radio</th>\n",
       "      <td>0.189</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>21.89</td>\n",
       "      <td>&lt;0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newspaper</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.8599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Coefficient  Std. error  t-statistic  p-value\n",
       "Intercept        2.939      0.3119         9.42  <0.0001\n",
       "TV               0.046      0.0014        32.81  <0.0001\n",
       "radio            0.189      0.0086        21.89  <0.0001\n",
       "newspaper       -0.001      0.0059        -0.18   0.8599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1.1 Replicating the Regression Table (9 points)\n",
    "!pip install ISLP\n",
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/Advertising.csv\"\n",
    "Advertising = pd.read_csv(url)\n",
    "display(Advertising.head())\n",
    "\n",
    "\n",
    "# Fit the model and display the summary\n",
    "import statsmodels.api as sm\n",
    "X = Advertising[['TV', 'radio', 'newspaper']]\n",
    "X = sm.add_constant(X)  # Adds a constant term to the predictor\n",
    "y = Advertising['sales']\n",
    "model = sm.OLS(y, X).fit()\n",
    "#print(model.summary())\n",
    "\n",
    "# Create a regression table\n",
    "import numpy as np\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    \"Coefficient\": model.params,\n",
    "    \"Std. error\": model.bse,\n",
    "    \"t-statistic\": model.tvalues,\n",
    "    \"p-value\": model.pvalues\n",
    "})\n",
    "\n",
    "table[\"Coefficient\"] = table[\"Coefficient\"].round(3)\n",
    "table[\"Std. error\"]  = table[\"Std. error\"].round(4)\n",
    "table[\"t-statistic\"] = table[\"t-statistic\"].round(2)\n",
    "\n",
    "table[\"p-value\"] = table[\"p-value\"].apply(lambda p: \"<0.0001\" if p < 0.0001 else round(p,4))\n",
    "\n",
    "table = table.rename(index={'const': 'Intercept'})\n",
    "\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60bc20",
   "metadata": {},
   "source": [
    "### 1.2 Hypotheses for the p-values (7 points)\n",
    "\n",
    "For each predictor, the null hypothesis states that its coefficient is equal to zero.  \n",
    "In the context of the Advertising data, this means:\n",
    "\n",
    "- **TV**: The null hypothesis is that TV advertising has no effect on sales, after controlling for radio and newspaper.  \n",
    "- **Radio**: The null hypothesis is that radio advertising has no effect on sales, after controlling for TV and newspaper.  \n",
    "- **Newspaper**: The null hypothesis is that newspaper advertising has no effect on sales, after controlling for TV and radio.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e396908",
   "metadata": {},
   "source": [
    "### 1.3 Interpreting the Results (7 points)\n",
    "\n",
    "Based on the p-values from the regression output:\n",
    "\n",
    "- **TV**: The p-value is very small (<0.0001), so TV advertising has a strong, statistically significant positive relationship with sales.  \n",
    "- **Radio**: The p-value is also very small (<0.0001), so radio advertising likewise shows a statistically significant positive relationship with sales.  \n",
    "- **Newspaper**: The p-value is large (about 0.86), so there is no statistical evidence that newspaper advertising is related to sales.  \n",
    "\n",
    "**Conclusion:** TV and radio advertising both significantly increase sales, while newspaper advertising does not appear to have a meaningful effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0bc76",
   "metadata": {},
   "source": [
    "### Question 2 (10 points)\n",
    "\n",
    "**K-Nearest Neighbors (KNN) Overview**  \n",
    "The K-Nearest Neighbors (KNN) method is a non-parametric, instance-based learning approach.  \n",
    "When predicting the outcome for a new observation, the algorithm looks for the **K training observations that are closest** to it in the feature space, where “closeness” is usually measured by Euclidean distance. The new observation’s prediction is then based on these neighbors.\n",
    "\n",
    "**KNN Classifier**  \n",
    "- Used for classification problems (predicting categories).  \n",
    "- The algorithm finds the K nearest neighbors and assigns the most common class among them (majority vote) to the new observation.  \n",
    "- Example: If 3 of the 5 nearest neighbors are “Yes” and 2 are “No,” the new observation is classified as “Yes.”\n",
    "\n",
    "**KNN Regression**  \n",
    "- Used for regression problems (predicting continuous values).  \n",
    "- The algorithm finds the K nearest neighbors and takes the **average or weighted average** of their target values as the prediction.  \n",
    "- Example: If the 3 nearest neighbors have house prices of 100k, 110k, and 120k, the predicted price is about 110k.\n",
    "\n",
    "**Key Differences**  \n",
    "| Aspect        | KNN Classifier (Classification)     | KNN Regression (Regression)   |\n",
    "|---------------|-------------------------------------|--------------------------------|\n",
    "| Output        | A class label (e.g., Yes/No)        | A continuous value (e.g., price) |\n",
    "| Decision rule | Majority vote among neighbors       | Average or weighted average of neighbors’ values |\n",
    "\n",
    "**Role of Distance**  \n",
    "“Distance” means how close two points are in terms of their features.  \n",
    "The most common metric is **Euclidean distance**, which is the straight-line distance between two points in the feature space. If two observations have very similar feature values, their distance is small, and they are considered neighbors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bd16516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Q3 Setup: helpers & data generators ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Design matrices\n",
    "def dm_linear(X):\n",
    "    #Linear model with intercept\n",
    "    return sm.add_constant(pd.DataFrame({'X': X}))\n",
    "\n",
    "def dm_cubic(X):\n",
    "    #Cubic model with intercept\n",
    "    return sm.add_constant(pd.DataFrame({'X': X, 'X2': X**2, 'X3': X**3}))\n",
    "\n",
    "# Fit and compute RSS\n",
    "def fit_and_rss(X, y, dm_fn):\n",
    "    #Fit OLS with a given design-matrix function and return (RSS, fitted_results).\n",
    "    Xdm = dm_fn(X)\n",
    "    res = sm.OLS(y, Xdm).fit()\n",
    "    rss = float(np.sum(res.resid**2))\n",
    "    return rss, res\n",
    "\n",
    "# Simulators\n",
    "def sim_linear_truth(n=100, beta0=2.0, beta1=3.0, noise_sd=1.0, rng=None):\n",
    "    #Generate data from a linear truth: y = beta0 + beta1 * X + noise.\n",
    "    rng = rng or np.random.default_rng()\n",
    "    X = rng.normal(size=n)\n",
    "    y = beta0 + beta1 * X + rng.normal(scale=noise_sd, size=n)\n",
    "    return X, y\n",
    "\n",
    "def sim_nonlinear_truth(n=100, beta0=2.0, beta1=1.0, quad=0.8, cubic=0.3, noise_sd=1.0, rng=None):\n",
    "    #Generate data from a nonlinear truth: y = beta0 + beta1*X + quad*X^2 + cubic*X^3 + noise.\n",
    "    rng = rng or np.random.default_rng()\n",
    "    X = rng.normal(size=n)\n",
    "    f = beta0 + beta1*X + quad*(X**2) + cubic*(X**3)\n",
    "    y = f + rng.normal(scale=noise_sd, size=n)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2996c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3(a) — Training RSS (true linear):\n",
      "  Linear RSS (train): 113.029\n",
      "  Cubic  RSS (train): 112.994\n",
      "Conclusion: Cubic training RSS is no greater than Linear training RSS (nested model & OLS minimizes RSS).\n"
     ]
    }
   ],
   "source": [
    "# === Q3(a): Training RSS (linear truth, fixed seed) ===\n",
    "rng = np.random.default_rng(2025)\n",
    "\n",
    "# Generate training data under a linear truth\n",
    "X_tr, y_tr = sim_linear_truth(n=100, beta0=2.0, beta1=3.0, noise_sd=1.0, rng=rng)\n",
    "\n",
    "# Fit linear vs cubic on training data; compare training RSS\n",
    "rss_lin_tr, res_lin = fit_and_rss(X_tr, y_tr, dm_linear)\n",
    "rss_cub_tr, res_cub = fit_and_rss(X_tr, y_tr, dm_cubic)\n",
    "\n",
    "print(\"Q3(a) — Training RSS (true linear):\")\n",
    "print(f\"  Linear RSS (train): {rss_lin_tr:.3f}\")\n",
    "print(f\"  Cubic  RSS (train): {rss_cub_tr:.3f}\")\n",
    "print(\"Conclusion: Cubic training RSS is no greater than Linear training RSS (nested model & OLS minimizes RSS).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920fdb0",
   "metadata": {},
   "source": [
    "**Q3 (a)**\n",
    "\n",
    "The cubic model is more flexible because it includes the linear model as a special case (when β₂ = 0 and β₃ = 0, the cubic model reduces to the linear model). Since OLS always finds the coefficients that minimize the training RSS, the cubic regression searches over a larger set of possible fits. Therefore, the cubic training RSS will always be less than or equal to the linear training RSS.\n",
    "\n",
    "In our simulation with a true linear relationship, the training RSS for the linear model was 113.029, while for the cubic model it was slightly lower at 112.994, confirming this theoretical result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d3ef690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3(b) — Average Test RSS over trials (true linear):\n",
      "  Linear Test RSS (avg): 1016.97\n",
      "  Cubic  Test RSS (avg): 1055.15\n",
      "Conclusion: Linear has lower average test RSS (better generalization when the truth is linear).\n"
     ]
    }
   ],
   "source": [
    "# === Q3(b): Test RSS (linear truth, average over many trials) ===\n",
    "def avg_test_rss_linear_truth(n_train=100, n_test=1000, trials=200, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    lin_list, cub_list = [], []\n",
    "    for _ in range(trials):\n",
    "        # Training & test from same linear truth\n",
    "        X_tr, y_tr = sim_linear_truth(n=n_train, beta0=2.0, beta1=3.0, noise_sd=1.0, rng=rng)\n",
    "        X_te, y_te = sim_linear_truth(n=n_test,  beta0=2.0, beta1=3.0, noise_sd=1.0, rng=rng)\n",
    "\n",
    "        # Fit on training\n",
    "        _, res_lin = fit_and_rss(X_tr, y_tr, dm_linear)\n",
    "        _, res_cub = fit_and_rss(X_tr, y_tr, dm_cubic)\n",
    "\n",
    "        # Test RSS\n",
    "        pred_lin = res_lin.predict(dm_linear(X_te))\n",
    "        pred_cub = res_cub.predict(dm_cubic(X_te))\n",
    "        lin_list.append(float(np.sum((y_te - pred_lin)**2)))\n",
    "        cub_list.append(float(np.sum((y_te - pred_cub)**2)))\n",
    "\n",
    "    return np.mean(lin_list), np.mean(cub_list)\n",
    "\n",
    "lin_te_avg, cub_te_avg = avg_test_rss_linear_truth()\n",
    "print(\"Q3(b) — Average Test RSS over trials (true linear):\")\n",
    "print(f\"  Linear Test RSS (avg): {lin_te_avg:.2f}\")\n",
    "print(f\"  Cubic  Test RSS (avg): {cub_te_avg:.2f}\")\n",
    "print(\"Conclusion: Linear has lower average test RSS (better generalization when the truth is linear).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddc029",
   "metadata": {},
   "source": [
    "**Q3 (b)**\n",
    "\n",
    "When we use test RSS instead of training RSS, the result can change. Even though the cubic model always achieves a lower (or equal) training RSS, it may overfit the noise in the training data. Since the true relationship is linear, the linear regression model should have a lower test RSS on average.\n",
    "\n",
    "In our simulation, the average test RSS for the linear model was 1016.97, compared to 1055.15 for the cubic model. This confirms the expectation: while the cubic model can fit the training data slightly better, the linear model generalizes better to unseen test data when the underlying relationship is truly linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "459634af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3(c) — Training RSS (true nonlinear):\n",
      "  Linear RSS (train): 356.388\n",
      "  Cubic  RSS (train): 95.794\n",
      "Conclusion: Cubic training RSS is no greater than Linear training RSS; with nonlinearity, Cubic often strictly smaller.\n"
     ]
    }
   ],
   "source": [
    "# === Q3(c): Training RSS (nonlinear truth, fixed seed) ===\n",
    "rng = np.random.default_rng(1314)\n",
    "\n",
    "# Generate training data under a nonlinear truth (you may tweak quad/cubic/noise_sd)\n",
    "X_tr, y_tr = sim_nonlinear_truth(n=100, beta0=2.0, beta1=1.0, quad=0.8, cubic=0.3, noise_sd=1.0, rng=rng)\n",
    "\n",
    "rss_lin_tr, _ = fit_and_rss(X_tr, y_tr, dm_linear)\n",
    "rss_cub_tr, _ = fit_and_rss(X_tr, y_tr, dm_cubic)\n",
    "\n",
    "print(\"Q3(c) — Training RSS (true nonlinear):\")\n",
    "print(f\"  Linear RSS (train): {rss_lin_tr:.3f}\")\n",
    "print(f\"  Cubic  RSS (train): {rss_cub_tr:.3f}\")\n",
    "print(\"Conclusion: Cubic training RSS is no greater than Linear training RSS; with nonlinearity, Cubic often strictly smaller.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2322894",
   "metadata": {},
   "source": [
    "**Q3 (c)**\n",
    "\n",
    "This case differs from part (a) because the true relationship is not linear, so the linear model is misspecified. However, the cubic model still nests the linear model (if β₂ = β₃ = 0, the cubic reduces to the linear). Since OLS minimizes the residual sum of squares, the cubic regression cannot have a larger training RSS than the linear regression.\n",
    "\n",
    "In our simulation, the training RSS for the linear model was 356.388, while the cubic model achieved a much smaller value of 95.794. This confirms the expectation: when the true function is nonlinear, the cubic regression typically attains a strictly lower training RSS than the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10959ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3(d) — Average Test RSS over trials (true nonlinear):\n",
      "  Linear Test RSS (avg): 2977.71\n",
      "  Cubic  Test RSS (avg): 1056.17\n",
      "Conclusion: It depends (bias–variance trade-off). Strong nonlinearity & moderate noise → cubic wins; otherwise linear may generalize better.\n"
     ]
    }
   ],
   "source": [
    "# === Q3(d): Test RSS (nonlinear truth, average over many trials) ===\n",
    "def avg_test_rss_nonlinear_truth(n_train=100, n_test=1000, trials=200,\n",
    "                                 quad=0.8, cubic=0.3, noise_sd=1.0, seed=99):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    lin_list, cub_list = [], []\n",
    "    for _ in range(trials):\n",
    "        # Training & test from the same nonlinear truth\n",
    "        X_tr, y_tr = sim_nonlinear_truth(n=n_train, beta0=2.0, beta1=1.0,\n",
    "                                         quad=quad, cubic=cubic, noise_sd=noise_sd, rng=rng)\n",
    "        X_te, y_te = sim_nonlinear_truth(n=n_test,  beta0=2.0, beta1=1.0,\n",
    "                                         quad=quad, cubic=cubic, noise_sd=noise_sd, rng=rng)\n",
    "\n",
    "        # Fit on training\n",
    "        _, res_lin = fit_and_rss(X_tr, y_tr, dm_linear)\n",
    "        _, res_cub = fit_and_rss(X_tr, y_tr, dm_cubic)\n",
    "\n",
    "        # Test RSS\n",
    "        pred_lin = res_lin.predict(dm_linear(X_te))\n",
    "        pred_cub = res_cub.predict(dm_cubic(X_te))\n",
    "        lin_list.append(float(np.sum((y_te - pred_lin)**2)))\n",
    "        cub_list.append(float(np.sum((y_te - pred_cub)**2)))\n",
    "\n",
    "    return np.mean(lin_list), np.mean(cub_list)\n",
    "\n",
    "lin_te_avg, cub_te_avg = avg_test_rss_nonlinear_truth(quad=0.8, cubic=0.3, noise_sd=1.0)\n",
    "print(\"Q3(d) — Average Test RSS over trials (true nonlinear):\")\n",
    "print(f\"  Linear Test RSS (avg): {lin_te_avg:.2f}\")\n",
    "print(f\"  Cubic  Test RSS (avg): {cub_te_avg:.2f}\")\n",
    "print(\"Conclusion: It depends (bias–variance trade-off). Strong nonlinearity & moderate noise → cubic wins; otherwise linear may generalize better.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086be756",
   "metadata": {},
   "source": [
    "**Q3(d)**\n",
    "\n",
    "When we talk about **test RSS**, we mean the model’s *generalization ability* — how well it predicts new data not used in training. A model that only memorizes training data (low training RSS) may still perform poorly on test data if it does not generalize well.  \n",
    "\n",
    "**Bias–variance trade-off:**  \n",
    "- **Bias**: error from assuming an overly simple model (e.g., forcing a straight line to fit a curve).  \n",
    "- **Variance**: error from fitting training data too closely, including noise.  \n",
    "- Linear models usually have higher bias but lower variance.  \n",
    "- Cubic models usually have lower bias but higher variance (risk of overfitting).  \n",
    "\n",
    "**Implications:**  \n",
    "- If nonlinearity is strong and cubic terms capture it without overfitting, the cubic model will likely have lower test RSS.  \n",
    "- If the relationship is only slightly nonlinear or noisy, the linear model may generalize better.  \n",
    "\n",
    "**Simulation result:**  \n",
    "- Linear test RSS (avg): 2977.71  \n",
    "- Cubic test RSS (avg): 1056.17  \n",
    "\n",
    "This confirms that under strong nonlinearity, the cubic model generalizes better than the linear one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b4f21ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimate (beta_hat): 1.976242377442051\n",
      "Standard error: 0.11694837274226326\n",
      "t-statistic: 16.898417063035104\n",
      "p-value: 6.231546010056513e-31\n"
     ]
    }
   ],
   "source": [
    "# Q4(a) — Simple linear regression of y ~ x (NO intercept)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 1) Generate data\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = 2 * x + rng.normal(size=100)\n",
    "\n",
    "# 2) Fit OLS without intercept:\n",
    "X = pd.DataFrame({'x': x})      \n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# 3) Extract results\n",
    "beta_hat = model.params['x']\n",
    "se_beta = model.bse['x']\n",
    "t_stat   = model.tvalues['x']\n",
    "p_value  = model.pvalues['x']\n",
    "\n",
    "print(\"Coefficient estimate (beta_hat):\", beta_hat)\n",
    "print(\"Standard error:\", se_beta)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc38425",
   "metadata": {},
   "source": [
    "### Q4(a) Report\n",
    "\n",
    "- **Estimated coefficient (β̂):** 1.976  \n",
    "- **Standard error:** 0.117  \n",
    "- **t-statistic:** 16.90  \n",
    "- **p-value:** 6.23 × 10⁻³¹  \n",
    "\n",
    "**Comment:**  \n",
    "The estimated coefficient is very close to the true value of 2, which makes sense because the data were generated from the model `y = 2x + ε`.  \n",
    "\n",
    "The t-statistic is very large (≈ 16.9) and the p-value is essentially zero, so we strongly reject the null hypothesis `H0: β = 0`.  \n",
    "\n",
    "This indicates that x is highly significant in explaining y when no intercept is included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fe43328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimate (beta_hat): 0.37574368103348865\n",
      "Standard error: 0.022235436587455238\n",
      "t-statistic: 16.898417063035104\n",
      "p-value: 6.231546010056513e-31\n"
     ]
    }
   ],
   "source": [
    "# Q4(b) — Simple linear regression of x ~ y (NO intercept)\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame({'y': y})   # predictor\n",
    "y_resp = x                   # response\n",
    "\n",
    "# no intercept\n",
    "model_b = sm.OLS(y_resp, X).fit()\n",
    "\n",
    "beta_hat = model_b.params.iloc[0]\n",
    "se       = model_b.bse.iloc[0]\n",
    "t_stat   = model_b.tvalues.iloc[0]\n",
    "p_val    = model_b.pvalues.iloc[0]\n",
    "\n",
    "\n",
    "print(\"Coefficient estimate (beta_hat):\", beta_hat)\n",
    "print(\"Standard error:\", se)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a1ab8b",
   "metadata": {},
   "source": [
    "### Q4(b) Report\n",
    "\n",
    "- **Estimated coefficient (β̂):** 0.376  \n",
    "- **Standard error:** 0.022  \n",
    "- **t-statistic:** 16.90  \n",
    "- **p-value:** 6.23 × 10⁻³¹  \n",
    "\n",
    "**Comment:**  \n",
    "The estimated coefficient is close to the theoretical value of 0.4, which is the expected slope when regressing x on y without an intercept in this data-generating process.  \n",
    "\n",
    "The t-statistic is very large and the p-value is essentially zero, so we strongly reject the null hypothesis `H0: β = 0`.  \n",
    "\n",
    "This indicates that y is highly significant in explaining x when no intercept is included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1160b",
   "metadata": {},
   "source": [
    "### Q4(c)\n",
    "\n",
    "The results from (a) and (b) are not simple reciprocals of each other.\n",
    "\n",
    "In part (a), regressing y on x gives an estimated slope near 2, which matches the true data-generating process.  \n",
    "\n",
    "In part (b), regressing x on y yields an estimated slope near 0.4, not 0.5, because the OLS formulas use different denominators:  \n",
    "- **y on x**:  \n",
    "  $$\n",
    "  \\hat{\\beta} = \\frac{\\sum x_i y_i}{\\sum x_i^2}\n",
    "  $$  \n",
    "\n",
    "- **x on y**:  \n",
    "  $$\n",
    "  \\hat{\\beta} = \\frac{\\sum x_i y_i}{\\sum y_i^2}\n",
    "  $$  \n",
    "\n",
    "Thus, the two regression slopes are related but not inverses of one another. The difference arises from how OLS minimizes squared errors depending on which variable is treated as the response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073dd0b",
   "metadata": {},
   "source": [
    "### Q4(d)\n",
    "\n",
    "**Algebra derivation**  \n",
    "For simple linear regression without an intercept  \n",
    "\n",
    "$$\n",
    "y_i = \\beta x_i + \\varepsilon_i\n",
    "$$  \n",
    "\n",
    "- The slope estimate is  \n",
    "\n",
    "$$\n",
    "\\hat\\beta = \\frac{\\sum x_i y_i}{\\sum x_i^2}.\n",
    "$$  \n",
    "\n",
    "- The RSS is  \n",
    "\n",
    "$$\n",
    "\\sum (y_i - \\hat\\beta x_i)^2 = \\sum y_i^2 - \\frac{(\\sum x_i y_i)^2}{\\sum x_i^2}.\n",
    "$$  \n",
    "\n",
    "- The standard error of beta_hat is  \n",
    "\n",
    "$$\n",
    "SE(\\hat\\beta) = \\sqrt{\\frac{\\text{RSS}}{(n-1)\\sum x_i^2}}.\n",
    "$$  \n",
    "\n",
    "Putting these together, the t-statistic is  \n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat\\beta}{SE(\\hat\\beta)} \n",
    "  = \\frac{\\sqrt{n-1}\\,\\sum x_i y_i}{\\sqrt{\\left(\\sum x_i^2\\right)\\left(\\sum y_i^2\\right) - \\left(\\sum x_i y_i\\right)^2}}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73074112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t (statsmodels): 16.898417063035104\n",
      "t (formula)    : 16.898417063035094\n",
      "Difference     : 1.0658141036401503e-14\n"
     ]
    }
   ],
   "source": [
    "# Q4(d) Numerical verification \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = 2 * x + rng.normal(size=100)\n",
    "\n",
    "X = pd.DataFrame({'x': x})        \n",
    "fit = sm.OLS(y, X).fit()\n",
    "t_statsmodels = fit.tvalues.iloc[0]  \n",
    "\n",
    "Sxx = np.sum(x**2)\n",
    "Syy = np.sum(y**2)\n",
    "Sxy = np.sum(x*y)\n",
    "n = len(x)\n",
    "\n",
    "t_formula = (np.sqrt(n-1) * Sxy) / np.sqrt(Sxx*Syy - Sxy**2)\n",
    "\n",
    "print(\"t (statsmodels):\", t_statsmodels)\n",
    "print(\"t (formula)    :\", t_formula)\n",
    "print(\"Difference     :\", abs(t_statsmodels - t_formula))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803fd13",
   "metadata": {},
   "source": [
    "**Conclusion**  \n",
    "The t-statistic from `statsmodels` and from the closed-form expression are numerically identical (up to rounding error).  \n",
    "This confirms that the derived algebraic formula for the t-statistic in the no-intercept regression is correct.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b59f3",
   "metadata": {},
   "source": [
    "### Q4(e) \n",
    "\n",
    "The t-statistic is the same whether we regress y on x or x on y (without intercept).  \n",
    "This is because the closed-form formula for the t-statistic is symmetric in x and y:  \n",
    "\n",
    "$$\n",
    "t = \\frac{\\sqrt{n-1}\\,\\sum x_i y_i}{\\sqrt{(\\sum x_i^2)(\\sum y_i^2) - (\\sum x_i y_i)^2}}\n",
    "$$\n",
    "\n",
    "Swapping x and y does not change either the numerator or the denominator.  \n",
    "Therefore, both regressions yield the same t-value.  \n",
    "Intuitively, this test is really about whether x and y are linearly related, and that relationship is symmetric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a0f614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t (y on x, with intercept): 16.734055202403045\n",
      "t (x on y, with intercept): 16.734055202403038\n",
      "t (from correlation r)    : 16.734055202403038\n",
      "Differences:\n",
      " |t_y_on_x - t_x_on_y|    : 7.105427357601002e-15\n",
      " |t_y_on_x - t_from_r|    : 7.105427357601002e-15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = 2 * x + rng.normal(size=100)\n",
    "n = len(x)\n",
    "\n",
    "# y on x WITH intercept \n",
    "X1 = sm.add_constant(pd.DataFrame({'x': x}))  # add intercept\n",
    "fit_y_on_x = sm.OLS(y, X1).fit()\n",
    "t_y_on_x = fit_y_on_x.tvalues.loc['x']  # t for slope of x\n",
    "\n",
    "# x on y WITH intercept \n",
    "X2 = sm.add_constant(pd.DataFrame({'y': y}))  # add intercept\n",
    "fit_x_on_y = sm.OLS(x, X2).fit()\n",
    "t_x_on_y = fit_x_on_y.tvalues.loc['y']  # t for slope of y\n",
    "\n",
    "#  compute t from correlation formula \n",
    "r = np.corrcoef(x, y)[0, 1]\n",
    "t_from_r = r * np.sqrt((n - 2) / (1 - r**2))\n",
    "\n",
    "print(\"t (y on x, with intercept):\", t_y_on_x)\n",
    "print(\"t (x on y, with intercept):\", t_x_on_y)\n",
    "print(\"t (from correlation r)    :\", t_from_r)\n",
    "print(\"Differences:\")\n",
    "print(\" |t_y_on_x - t_x_on_y|    :\", abs(t_y_on_x - t_x_on_y))\n",
    "print(\" |t_y_on_x - t_from_r|    :\", abs(t_y_on_x - t_from_r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665175c4",
   "metadata": {},
   "source": [
    "### Q4(f)\n",
    "\n",
    "In simple linear regression **with an intercept**, the t-statistic for testing  \n",
    "H0 : beta_1 = 0 can be expressed as\n",
    "\n",
    "$$\n",
    "t = r \\sqrt{\\frac{n - 2}{1 - r^2}}\n",
    "$$\n",
    "\n",
    "\\(r\\) is the sample correlation between \\(x\\) and \\(y\\).\n",
    "\n",
    "Since correlation is symmetric Corr(x,y) = Corr(y,x), the t-statistics are the same whether we regress \\(y\\) on \\(x\\) or \\(x\\) on \\(y\\).\n",
    "\n",
    "**Numerical verification:**\n",
    "\n",
    "Both regressions (with intercept) and the correlation formula give t is about 16.73, with differences smaller than 10^-14.  \n",
    "This confirms the theoretical result.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
