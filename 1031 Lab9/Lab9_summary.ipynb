{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b297732",
   "metadata": {},
   "source": [
    "# Lab 9: Support Vector Machines — Summary\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Linear SVM and the Cost Parameter (C)\n",
    "\n",
    "**Experiment:**  \n",
    "Used the *Hitters* dataset with features `CHits` and `CWalks`, fitting two linear SVMs with `C = 0.1` and `C = 100`.\n",
    "\n",
    "**Findings:**\n",
    "- The parameter **C** controls the trade-off between **margin width** and **classification accuracy**.  \n",
    "- **Smaller C (0.1)** → wider margin, more support vectors, smoother boundary → less risk of overfitting.  \n",
    "- **Larger C (100)** → narrower margin, fewer support vectors, tighter fit → higher flexibility but possible overfitting.  \n",
    "- The boundary visually became sharper as C increased, confirming this effect.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Hyperparameter Tuning with Cross-Validation\n",
    "\n",
    "**Experiment:**  \n",
    "Performed a 5-fold GridSearchCV for `C = [0.01, 0.1, 1, 10, 100]` using a linear SVM.  \n",
    "Plotted mean CV accuracy vs. C on a log-scale.\n",
    "\n",
    "**Findings:**\n",
    "- **Cross-validation** helps identify the optimal regularization level.  \n",
    "- Accuracy increased rapidly from small C (underfitting) and plateaued around **C = 10**, the best trade-off point.  \n",
    "- Increasing C further gave no improvement, confirming diminishing returns beyond moderate regularization.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. RBF Kernel and Model Comparison\n",
    "\n",
    "**Experiment:**  \n",
    "Generated a synthetic non-linear dataset and trained RBF SVMs with `γ = 0.1, 1, 10` (using C = 1).  \n",
    "Visualized the decision boundary and plotted all three ROC curves.\n",
    "\n",
    "**Findings:**\n",
    "- The **RBF kernel** enables SVMs to learn **non-linear boundaries** by mapping data into higher-dimensional space.  \n",
    "- **γ controls model complexity:**\n",
    "  - Small γ → smooth, broad influence of each support vector → underfitting if too small.  \n",
    "  - Large γ → sharp, highly flexible boundaries → overfitting if too large.  \n",
    "- **Best performance:** γ = 0.1 (AUC = 0.959), achieving the best generalization on the test set.\n",
    "\n",
    "---\n",
    "\n",
    "## Overall Insights\n",
    "\n",
    "- SVMs balance **simplicity (wider margin)** and **fit (fewer errors)** through the hyperparameters **C** and **γ**.  \n",
    "- **Visualization** of decision boundaries and ROC curves clarifies how these parameters affect under- and overfitting.  \n",
    "- **Cross-validation** is essential for selecting hyperparameters that generalize well.  \n",
    "- Combining **data standardization, grid search, and visual analysis** provides a systematic workflow for robust SVM modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This lab demonstrated how to control and evaluate SVM model complexity through **C** and **γ**, how to tune them using cross-validation, and how to interpret their effects on margin width, support vectors, and generalization in both linear and non-linear settings.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
